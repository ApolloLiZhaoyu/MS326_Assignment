{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*ATTENTION: When hand in your homework, all print info has to be kept which means that output results of each cell could be seen in your submissions. Homework scores will be judged by those print info. So show us the best result in your experiment. More details can be found in assignment1_tutor.pdf.\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from MS326.datasets.fashion_mnist.utils import mnist_reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (58000, 785)\n",
      "Train labels shape:  (58000,)\n",
      "Validation data shape:  (2000, 785)\n",
      "Validation labels shape:  (2000,)\n",
      "Test data shape:  (10000, 785)\n",
      "Test labels shape:  (10000,)\n",
      "dev data shape:  (1000, 785)\n",
      "dev labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "def get_mnist_data(num_training=58000, num_validation=2000, num_test=10000, num_dev=1000):\n",
    "    \"\"\"\n",
    "    Load the Fashion_mnist dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw Fashion_mnist data\n",
    "    X_train, y_train = mnist_reader.load_mnist('MS326/datasets/fashion_mnist/data/fashion', kind='train')\n",
    "    X_test, y_test = mnist_reader.load_mnist('MS326/datasets/fashion_mnist/data/fashion', kind='t10k')\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0).astype('uint8')\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_mnist_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **MS325/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.389875\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file MS326/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from MS326.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(785, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ \n",
    "\n",
    "Since the weight matrix W is uniform randomly selected, the predicted probability of each class is uniform distribution and identically equals 1/10, where 10 is the number of classes. So the cross entroy for each example is -log(0.1), which should equal to the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.923917 analytic: 0.923912, relative error: 2.560896e-06\n",
      "numerical: -1.260936 analytic: -1.260948, relative error: 4.623783e-06\n",
      "numerical: 14.277905 analytic: 14.277891, relative error: 4.999640e-07\n",
      "numerical: -4.031204 analytic: -4.031207, relative error: 3.964219e-07\n",
      "numerical: 12.391775 analytic: 12.391770, relative error: 2.052228e-07\n",
      "numerical: -2.779025 analytic: -2.779032, relative error: 1.315932e-06\n",
      "numerical: 6.687064 analytic: 6.687044, relative error: 1.501497e-06\n",
      "numerical: -6.584529 analytic: -6.584545, relative error: 1.238465e-06\n",
      "numerical: -6.798101 analytic: -6.798105, relative error: 2.235408e-07\n",
      "numerical: 11.266984 analytic: 11.266979, relative error: 2.002628e-07\n",
      "numerical: -5.401413 analytic: -5.401415, relative error: 2.508529e-07\n",
      "numerical: -7.502249 analytic: -7.502256, relative error: 4.363905e-07\n",
      "numerical: -3.659020 analytic: -3.659024, relative error: 5.038131e-07\n",
      "numerical: -0.681744 analytic: -0.681747, relative error: 1.864726e-06\n",
      "numerical: -1.415182 analytic: -1.415198, relative error: 5.823658e-06\n",
      "numerical: 14.148340 analytic: 14.148329, relative error: 4.128357e-07\n",
      "numerical: -0.338588 analytic: -0.338591, relative error: 3.914064e-06\n",
      "numerical: -3.445687 analytic: -3.445697, relative error: 1.472940e-06\n",
      "numerical: -3.507277 analytic: -3.507292, relative error: 2.158470e-06\n",
      "numerical: 1.243849 analytic: 1.243846, relative error: 1.294475e-06\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from MS326.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.389875e+00 computed in 0.257029s\n",
      "vectorized loss: 2.389875e+00 computed in 0.001997s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from MS326.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-08 reg 5.000000e+02 train accuracy: 0.168741 val accuracy: 0.168000\n",
      "lr 1.000000e-08 reg 1.000000e+03 train accuracy: 0.217500 val accuracy: 0.208000\n",
      "lr 1.000000e-08 reg 5.000000e+03 train accuracy: 0.265897 val accuracy: 0.261500\n",
      "lr 1.000000e-07 reg 5.000000e+02 train accuracy: 0.712914 val accuracy: 0.715500\n",
      "lr 1.000000e-07 reg 1.000000e+03 train accuracy: 0.722879 val accuracy: 0.722000\n",
      "lr 1.000000e-07 reg 5.000000e+03 train accuracy: 0.682190 val accuracy: 0.687000\n",
      "lr 5.000000e-07 reg 5.000000e+02 train accuracy: 0.705534 val accuracy: 0.695500\n",
      "lr 5.000000e-07 reg 1.000000e+03 train accuracy: 0.737638 val accuracy: 0.740000\n",
      "lr 5.000000e-07 reg 5.000000e+03 train accuracy: 0.617259 val accuracy: 0.607500\n",
      "best validation accuracy achieved during cross-validation: 0.740000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.65 on the validation set.\n",
    "from MS326.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-8, 5e-7, 1e-7]            # Modify it as you wish\n",
    "regularization_strengths = [5e2, 1e3, 5e3]  # Modify it as you wish\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500)\n",
    "        \n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        \n",
    "        train_accuracy = np.mean(y_train == y_train_pred)\n",
    "        val_accuracy = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, reg)] = train_accuracy, val_accuracy\n",
    "        \n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = softmax\n",
    "\n",
    "        \n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.676600\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$\n",
    "\n",
    "True.\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAADfCAYAAADr0ViNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztvXm0bUd13vubahAS6hDqdaWr5kqAEDJIAhkswxDIOCSWgTcyaIwxCiHvYQe3YJM42JYc4xA/HgZiA3mxsWkMyA9DwCbCDs9ISDQiAmEJCQHqm6u+7xBqKn+s9d1d5zur9tlnn3vPOQvmN8YZ++y116pVNVetqm/OmnNWlFJIJBKJxHix3VpXIJFIJBIrQw7kiUQiMXLkQJ5IJBIjRw7kiUQiMXLkQJ5IJBIjRw7kiUQiMXL8UA/kEXFeRJzW+O3wiLhvlauUWGVExKERUSJih/772RHx+rWuVyKxNbHuBvKIuK/6eywiHqy+v3pr3aeUcmUpZdcl6tKcCLY1VksOY0JEXF3J4eaI+IuImPoMf5RRyeveiLgrIr4cEW+IiHX33q8lIuLnIuKCvl/dGBFnRcRJKyxzVQnDunugpZRd9QdcC5xaHfur1ahDRGy31p19uXIQ41xLrFIdTu1lchzwLOCtq3DPFSEitl/D259aStkN2Ai8HXgL8OdDJ65xPdcEEfEbwLuAPwT2Aw4B3gu8ZC3rtVysu4F8uYiIXSLioxFxe886vhYRe1enHNYzkXsj4nMRsVd/3aaIKFU550XEf4yIrwD3Ax8DngO8v5+p37WqDVsCEfEHEXFmRHwsIu4Ffj4iHh8R7+lZxQ0R8c6IeFx//usj4uzq+h16k8Oh/fefiYhv93K6PiJ+vTr3ZyPin3r5nhcRx1S/XR8RvxkRFwMPrFLzKaXcAJwFHNMzz1OqOp0eER9Zqox+wn5rRFwTEbdExIciYo/+t89FxBvt/H+KiP+j//8pEfE/I+KOiPhORLy8Ou8vI+J9EfE/IuJ+4OSt1Oy5UUq5u5TyGeAVwGsj4pihekbEThHxjoi4ttd63h8ROwNExN4R8Xd9P7gjIs4V4YmIt/R97t5eHi9cw+bOhP5Z/z7wb0spnyyl3F9KebiU8rellN/sZfGuiNjc/70rInbqr31iL4tbI+LO/v8N/W9vA34S+JN+7PiTbd2W0Q/kwL8CdgE2AE8Cfgn4fvX7zwGvpZttnwD8xpSyXgO8DtgdeDXwFeANPQv+ta1f9RXjZcBHgT2AM4HfBU4AjgWeCfwE8O9nLOsvgH/ds7djgXMAIuJZwH8DXk8n3w8An9YE0eOVwIv7eqwKIuJg4J8DF66gmNP6v5OBw4FdAb10HwVeVd3vaDpW+9mIeALwP/tz9u3Pe29EPK0q++eAtwG7AeetoI5bFaWUrwHX0w00sLie/xk4CngGsAk4iK5fAbypv3Yfuvfpt4ESEU8G3gg8q+8/Pw1cvQrNWSmeAzwe+FTj9/8A/DidLH4MeDYTDXA7undmIx2Lf5C+75RS/gNwLvDGfux4I9sYPwwD+cPA3sCmUsqjpZQLSin1Iuafl1K+V0p5APj/6B5KCx8opXy7n5Uf2ZaV3ko4r2cPj5VSHqSbfE4vpdxaSrmFjm28ZsayHgaOjojdSil3lFK+0R//P4H3llL+Vy/fD/THn1Vd++5SyvV9HbY1/ntE3EU36JxDpxLPi1cD7+zXS+6jm/Re2ZuIPgU8IyI2Vud+spTyEPAzwNWllL8opTzSy+pvgH9Zlf3pUsqX+mdTE4v1gM3AXv3/W+oJPAT8G+DX+z5wL518X9mf+zBwALCxf0fOLV2ypkeBnej6z46llKtLKVesaovmw5OA26a8668Gfr+Ucksp5VbgDPr3qZRyeynlb0opD/Ryehvw/FWp9QBGNZBHxPaxcBHwQOAvgc8Df92rdm+Phbbam6r/H6BjXS1ct/VrvU3h9T0AuKb6fg0do5oFLwN+Frg2uoWaE/vjG4G39Or0Xf0geoCVu5pye2kpZc9SysZSyi+tcPI4kMXy2gHYr385P8tkEHsloLWJjcCJJpNXA/tXZa3nvnQQcEf/f13Pfei0269X7fpcfxzg/wYuB/4hIq6MiH8HUEq5HPg14HTgloj4eP9urnfcDuwd7bWdof5xIGwx6f7X3ix3D/BFYM9Yo3WGUQ3kPSPctfrbXEr5QSnl9FLKU4GT6Aakeb06PBXkek8N6fW7kW6QEQ4Bbuj/v5/uJRXqQYdSyvmllJ+lMxX8HfDx/qfrgDP6wVN/u5RS/npKPVYbU9s2BZtZLK9HgJv77x8DXhURzwF2Br7QH78OOMdksmsp5RerstZaJoPoTWUHMTH31PW8jc5E8LSqXXvIu6uUcm8p5U2llMOBU4HfkC28lPLRUspJdPIsdCaa9Y6v0JlhX9r4fah/bO7/fxPwZODEUsruwPP649F/rurzH9VAPoSIeEG/cLMdcA+d+vfoVir+Zjrb6VjwMeB3+0WpfYDfAbTo90/AsRHx9H7x6vd0UUTsHJ0L1u6llIeBe5nI8P8F/m1EPCs67BoRp/Z24vWCb9KZRHaMiBNYaOKYho8Bvx4Rh0XnxviHwJmVqv0/6F7k3++PP9Yf/zvgqIh4TX/PHXv5PHXrNWnrIiJ2j4ifoZugP1JKudjP6dv334A/joh9++sOioif7v//meicBILuXXsUeDQinty/hzvRDYwPsvXewW2GUsrddPb/P42Il/Yse8eIeHFE/BFd/3hrROwTnQPF7zJ5n3aja+dd0TlQ/J4Vv6pjx+gHcjpV55N0HesSOjPLx7ZS2e+iY2R3RcQ7t1KZ2xJn0A3YFwMXAecD/wmglHIp3UB1NvAdOlWwxmsBqYn/mokt8HzgF4H3AXcC3wV+fhu3Y7n4HeAIuvqdQbcIOQs+AHyYThZX0Q1Cv6wfe3v4J4FT6jJ7s8uL6Mwtm+nMd/+Zzk683vC30Xk1XUe3ePdOOgeBFt5CZz75at8XPk/HPAGO7L/fR8dm31tKOZuu3W+nY/Q30Wl1v73VW7INUEp5J50DxFuBW+nk9EbgvwN/AFxA9y5dDHyjPwbd2LAzXZu/SmeCqvFu4F/2Hi3v2cbNIEpuLJFIJBKjxg8DI08kEokfaeRAnkgkEiNHDuSJRCIxcuRAnkgkEiPHqiZa+tSnPjXTyupjjz224Pv111+/5f8HH+ziP7bbrpuDOk8oePTRztvpyU/uFtg3buzcPx/3uC6S/P777wfge9/7HgA333zzgt+///0u+G633XYD4LbbbltUr6c85SkL7qk6OF72spfF4A8D+LM/+7NlrTbrnmoPwB13dLEd3/nOdwD4whc6d+c99ugi5h9++GEAfvCDHwDwwANdSpQnPvGJC36/6667ALjnnnsAeN7zOtfYn/iJnwDgx37sx7bc86GHHgImcpNMBP/++te/fmaZvP/9759JJr5Qv88++2z5/9JLLwXgggsuAOCGGzp3+r326gIan/vc5wITGey0U+dwcvvtty/4VH9R2YceeigAxxzTpZu5775JELHO3X//zo19++0Xxoa4TN7whjfMLBOAc889dy7PhM2bN2/5X8/tvPM6N3I9v3333ReAU07pUtYce+yxAOy9d5e26Iorrlhw3de+9jUADjnkkAXnS47qkzCR+c4777ygXpKHy+Unf/InZ5bLO97xjmWNKfq88847t/z2spe9DIBNmzYBk/fgjDPOAOAjH+k8DvU8d9mlC1nYYYdu+HzqUzuv09/6rd8C4CUv6fJt3XRTF4v4zW9+E4BPfOITW+6pa/Tu+Vji39/85jdPlUky8kQikRg51jz1KUxmZDGs667rooYvvLDLh/Stb31ry7mHH9752D/96U8HYMOGDQA8/vGPByYzrtipZlGVrd/FsO6++25gwsDPOussYMLMAZ7znOcsuIdYjWsDLYY+D1RffeqeYjUHHTSJkD/wwC4aWtrKq17V5XpS21VP1V/MfMcddwQm7F7X6zq1R2xL7AEmjEuMTuxE9d1zzz0X3HtrwBm4NI7Pf/7zAHzpS1/a8ps0LTHo4447DoD99ttvwbWqn+Sr5y7Z6HextPPPPx+AT32qy7MkDRDg1FNPBeBJT3oSMJGzWOpVV121oMytBe8r6svSSg844IAt537mM58BJqxSbFlahJiqmLe/P5Kb2q1+cPHFXXyR3kv1GZgwU2k5ejZe5taUizNw4cQTu8wTRx555JZjasPnPte5gn/3u98FJjJ505veBEzeE73v6vPSWiQDabxPe1qXQ+3Zz342MHke9T0kb5Wld+zWW28FZh9TkpEnEonEyLEuGLlw7bXXAnDmmWcCkxlbrBsmTFrsUnBGqNlTM5pYgLNSHRcTE9OQTRDg05/+NDCZPU8+uUsvrdle7K22l84LZ1eqpxiUGLnaCxOGIEYjFnXvvfcuKEuMW+xTTPGRRx5Z0B4xJEHlqZ0wYXliDr52IfYltrISOBNXu6SxnXvuucBCdix7p+Sm567vgtYDdA/ZzCVfaTv6POywwwC48sorgYktHiY20Fe84hXARCuRfFWnum+tBN5X1A+OOOIIYPJ8L7rooi3XqJ/r+emZ61y3A7u2qb4jTUcajp6/tI6DDz54yz31XK6++mpg0jckY/Wheo1jXjgT1zPQmoZYtvoOTGzYer/V/yUTsWS9Xz7WSGaSrdYkpBnpuYuhw0RzueSSS4CJZUDvmLQ6yWopJCNPJBKJkWNNGblmONnExaxkY9JsX9v4NFOJMWg2FOMSg9DsqNlTxzXj6TrZeGUrFOMYYtdaqRcrk51N7XB73HLgrFPfxYTExJ/whC5XVc2aNZuLFe2+++4Lvgtug5QMXEZiImrPrrvuuuA8mLBiMR5dW9vRh9q1HPi1evZqlxie2I28imqon0iOapPqq9+lmbW0Gx0XY5fXgb4DXHbZZQBcfvnlAJxwwgkL7qF7rzQthjNx79N6XtIE1GdgwqT13G655ZYF57odWGXrnVRZ0hTVfrFpvTeSZ10vrevondPn1oAzcZUtBq76iInXWpEYtNqmvu1anMpWH1d/dK8v9TXJUP2hfh+11ifNxb3A3ONpKSQjTyQSiZFjTRi5ZjatFov9yF4kRiH7as16xLTdPtViUmIOblMXNFNrFhWblTZQl6GZWyvOYjfuH7sSiA2o/mLeuoc+a1an+mk2dwYhqEyV4V43rlnouF9fl6FzdU/Vf2t68EjOaqf6jTM92bth8rzFKFU/aRtqm3v2CO5ZIfgaTP27bNPqJ6qvnqHLc6XwNQ/Z8dWHdbxeF1A7dY60OfUd1VF1F9yGrndUx10LqOHasbTfG2+8cUGdVgK3iasears0D3mz1YxcMlA/Up9xrUTahr83gpi56qLz9S7UMlWZ0u71PLzMWbX8ZOSJRCIxcqwJI5ctSjPVOeecAyz28dYsVTNBZ4+aBcVOfHbXPXSeZsJWhKjqVjN41UcryGKEKkPX1Cx+udDKvViLGKG+q95D9tWW94Lb2VSGz/Kuxcxin5PcVKaYmVig7iG74TzQar/apWeoT/euqdmM6tHyF/e1FN2jXgeo4f3NfYnr/52Vunxl058XYrLu4eD2fmkotcaofq1PPTfB7db6Xc9bzNtjDXRvvRN1ueoLqodkLiYsedXRoLNCZevdU1mqp2v/ihLXvWGiXbk3l+Trfd29WPy7e4lJpnW/UP00tui7WLvqVPueT0My8kQikRg51oSRu81Js6RmbNm5fPaHyeq5GIBmOWcOYkzuieFeLipP5bitHCYzrvJRqEwxHrG+lh1+GjR7L+VR4jbnmpmrPh696usIqp/b7Dyi01naEHQPleWag+TpttZZ0JKJ2yzVX1xLg0lbxU59XUBwLcRZldqp9rhMh5in+x8LktE8Mqnv7W2QPFosu+6XLgd9qgxfU3I5eLv1KTnr3R2C30t10Ts4r1zqsgXVX77cilGRhigNGCbvr9qmZ+1jg+rn2p2/q/VaDSy2mddluwbjcS46bykkI08kEomRY039yGVzViZCZ1FD9mrNUM4U9KlZ0W2dbu/SPTTz+Wxb+8Hq/pq5ZV+Th4awktV3Z1uqv3uSDK2YO0sU1Fa3+dVtg0nb3T4vjUiobevO6Dz601fw54H7futesrE6I6/z4zhLckbpdmyV4WsTOs9zjkgjrBmT91vVX59DEbLzoKVptXL/1M/bGbTnHJJtVs9PcpCsVXfJWm2VHIbu6XBG7ux/OXDt099/MW95rQyxfl97cb9894xzTWtovWSoLvU7K7u5oknlcaR7SX7ptZJIJBI/IsiBPJFIJEaONTGteKpGmSikpklt1fdpCaLcNWipQBTfaMJV7iG1V/XVNVK3fRGkVu1nhZtUXJ1rtadW7/S/m1Zc3ZQqKzVOCY7c5CL1W+HNqlttjmgFG6ksN7EsB0OLl/Vx3Vsque5Rq/OuzrbSGbsJxRf7WimLdZ0n4YL2YvGQij0P3PznQW1qo5uF6vp6/T3Iyhf03Vwks5v6vOQkDPVbNxv4At/WCNn39MOCTBhD77mOuZnG+46nvBDc9Oepnd3FuS5LcnMzqO49q0ySkScSicTIsaqMXIuFmmWcrWmWdze+oQAVzWRyE2wtTmlmc4d7n4UFsYW6bqqP2Ee9zRqsLBxd7lGuYQzN4nV7hu6v+nl6XV+8VPCEUrE6M9KnzpPLVi0rl5u7H+qeztRmgdJ9ql2uATkDHwoL13Nu9QcPwffQc98CsLWYXj8PTwHbWjRbbkIkwUPavS6t0PEheAoDl1Nr4dSDYDycXajb6GWrvup30hTnSQMtrVFwmbuMVJd6jNEY4oFnXpbg6Qxc2/NNIvzdqK/xsH9PWNcKUHMkI08kEomRY1UZuc+SSop19NFHA5NZUoE3+r1mf2JarWRGPoOJWbmrltvD9ClbYG1vdVcraRZKr+tJgZaD1ga03i4PwBnSAlQv2TU9SZaCNXSeB/O0gqaE+jm4bd81ipYb6Dzw1MJaU/FAqFom3hYPRnFWK6am43Kn8/UBZ/Z1P3QbcOvZzsvIHaqDBytJXv5Zn+v2dGeVguSjvuBrN+r7roHVGq2nCBbc1j9LIJqjpQ27FucuuEPw1A9uT3eXQJeBBx+qnyrpX31vT0Hccl2cVSbJyBOJRGLkWFVG7vY0MVptbqzfZZv1mQ0mq72aPT0s2dPX+gq0M3dnn0qxWc+eHmLr18zjrSKo3qpvi2U5Cxhix6qPbPg+2/t6gqcpaKUDaKW1HYKv4M/DyCUTTzYkTUPBK9KQhmyZbo+WVuJseKkgKsnWWbZvuFDD+7nLbV4txRNTSS7OvHU/97ip6+brD+4J5MEvrmk5sxfUj2stwFmw9yeX6XKgNQ31DX9X3evD7dawOOGbyvT1AbcoCJKFs2hvz5DG6PZ074/TAqsWlD3TWYlEIpFYt1hVRu52VN84QmzYk9TLswMWh8W7/c0ZruBMw70RdFx25Hom1Dn1BhdD95iHabUSIXnqAfcSqWd3T2TkiZF842ldK0YrWThbE0PRc5iFkfuaw6yMoobLQvcXE/cNSdSO2r7rWlLLPuvwlKSCy27Iq8A9PVyr0uc8tuAabt/Wc3JPHb0rta+7xxQI+u5eRjrf+4jHYahNSrtRvxvOil0+vu3ecuB+/e7/Lhn4RiD18/UEYOpPvm7iWqavv0h2biVwRg+L2bq0LN8UZtZNa5KRJxKJxMixqozcV8g9ukwJfHwDhJpNOftqJcESWjYoZ/D63W1XdT0EZ0Qt+9Zy0LLDtSLVhhi5NBmxjxaDUHvcl9pt6i3vkLrslveQR8zOg9bWc+5B4h4VsHgrOk9v7DZi10a8HbpO6wyyjdeMybU9Z4nqJyvdGtDt1e6Z5W0aSrwkxurJ4jzK0tP4ul1bfcT974fgkbm+frXSZGJ1Gb6ZsW+AUSeE8w1tHO7RprJbcQKCb/w9ZJf3Z+YymTU1djLyRCKRGDnWxI/ctwcTy3G75lAOjVa0lduSPRJNzMPZi28262ymvsbtcZ4nYZ4IT88V4/bs1hZvdTSj2/0k11YKVkHnObt2r5EhtBi5aw4r8SN3X3TJpJWLp+4nYr0eDeqRjM7cfbMA14g8F8aQrd09N9wzZF4tRfdS+10O/tz1+5A3j+ThTNDL8BTHvs6l9LAbNmxY8PtQvVuxB8I8jFxliGG3NFfJSNpqLRP3NmmtVznbd61Ox7WW5mNQXa5rOK6tCLPKJBl5IpFIjByrysg9qtLZp7PklsdGjRYT9wxwboNueTG4f3qNls9x6/dZ0PIwafl0T7uHbxogeJlqu+7taxeew8RX72GxvIXWCv9yoHr5FnQtZj607VrL39n7Uiv3js4f8vyozx9aqxCk0bQyXC4X0lhbG4a4ZuKfdR1c29Jx91H33ENqi+QmW7tvFlH3lZZnlvedeTycxLQdvi40LROh91Ff+1oqb5B7mnhcx7QMoPJ31wbajozsTCQSiR8RrCojb/l8t7K3DeVTnmabrOG+u4JH5LlNUDa02l7vjMJzbre2epoFvl2Zsytf1R7y5XbvE9/k12XmLNVl6drMkCydTfk6wdBK/azwXOCtPNbuf1x7g7idv2Xvdxm08qy7/Ifa5d49rQyb82bLVJ90DyvPR+4aSv18da3k0fL80V4B3ne8/3nmyaGskC2ZumfWSiI7W33dtZehXE2ucQ5l06zr6/1P8Q1qZ8tvvmbXHn0rTUj2dV+TWQrJyBOJRGLkWFVG3rJb+UzsM2LNYFqeIp7jw3NEaMbTvTRrureK5xiu6+n12Rr2YLe1trKhCe4HXZfhawvOqAWXjcvCfW9bzLI+p+WJMA/79H7htnFnRt6vYLGd08t2P3HXQlxLFFxLqJmn9yWPYWhpibPCPa6kgbj9t5UJtP7Nman7vrs8nLV635Ct3D266nM8ErLF1JeDludVK8/JUH+UXCVP5d9XWzwuwy0FqoO0/NZmzXVf9LK0g5Eyv3q9l0Iy8kQikRg51iSys8XafPZxH+D6mOA+nn4vZ9gtG7tn2huywbstbyU7AwlD6wA1WsyxZnUefSh5SQtxH9uW94TvI+hZ4IY8EZbCPOyzZaNslT2Ulc6ff8u27dqG28QFt397psH6N8+bIfY7z/6lNdzDRnA26hpZ3RY901bcQivbpkcaeh/yXbNqtMrcGmhpP/4+u1Y0lN3U3zHBd+1paTwuU/WDId91wTOVerzDrEhGnkgkEiPHqjJyt72610drRhzy33RG4H7DLebt9jpns7L1DV3TynsizMO43ObqnjG+BjAkI2c8Lfu/l+VsSz6t2iHF7aFDOdAdXr959uxU/T0yUvIdYsMOl+PQ2kd9nsvCo0rVLn/GNdt1DwSvp86dd7d4sTdngu5PPi3/ue7ta0ae8dJt6Z4F0b1cVLdpvuutvDzevuVA7fDnp+fk2VKHdjCS5uT+362YE1+P0/Uq08/XPeu6+A5UnsdF8lb7lkIy8kQikRg51sRG3to5RXCWXc9kmrU1gy0nChQWe2x4HcTIh3ZHb0WHqV3z7ALutlfXKNwm7gyyhvv6tvyaW/mU3RfXPROGbNdeD2+HZ6OcBa4lLbV7kttJ62ta/uxL2e5buXw8b0qtcfhOPc7MWyxxVni73RvC14uGPG9aa0yCR366d0Urj7bKkTZXM8nWXqb+fId2W1oKLgvJWu+x6uHvec3IlevJ8zh59kj5i7vPt+cdb0UPD2lGqofGM9+tS94sSyEZeSKRSIwcq8rIfaZyNt3yW66ZrtunWh4vbiN3Vunl6Ltm8tqOqRm7xcRbmctmQcv3u1XWLIzcIz3dpu/RYp4d0a9zO3Fdb0G/uYfGrB4oQ2W18larvr4zTs3+XY7OBt07yTUHl4FnuPN1CJi02XOV+1rFPOsG9fWtfWhb/tpDUYyu+XlWSI88dBt5K7J3KI+2e2Z52UN261nh7fF+59qPmG8dBezZWFvax7T4Flj8Dqhd7l9enyvGLW8inTstl/wQkpEnEonEyJEDeSKRSIwcq2paabmAtUwWQ5sve1mt9LWtBRXfqMEXBodUMqWYbJk1XKVaDnxhcdZF26Hgl5Zboausrrb5+S7bofB7XyxsbRa9Epm4qccXGLXoNG0jjNYCb8u1TGiFkbsqXy/qufunu6N5H1su/LqWu1vLxRYmpkOp8L5JtqdpcFOZp8hoPe/adOHvjS9e63NWV7sa/sw9IMjfe33Wph9PvetjibtUumumJ9HyxdIhc47SAMhs7AFMKmvWBeBk5IlEIjFyrAkj9+++GOLuZ7ULjmZtzahehrNQv6en72wxrPqehx566NT2tJjvLPC2t9wPJZPWhhP1Oa7ZOEtROlRPnORajGtKtRYgZuaMrLXotBy4RuDPsLWVWn2ebzrhLootFutagLsv+kJr/RykxbXqtZJF8aE6L5UcbUgb8oAgZ37OcHVc8tR3d6nzDRLkIFDfo6UprmSx0/uh9ztfnJ2WHqCV8toZeCuRmj8PYeieKlvu1JKfytL3WROJJSNPJBKJkWNN3A99ZnYWpFlIs2ntfihGsOeeey64xt3JnKm73cvdEzXbynZVM3K3fbWCd6aFjLfgjLsVzLOUu2V9zOvldk+3NXs4vWszrQ0ohurfcm9bDlqpGrz/iFWKCe+9995bzlVbxCQ95a0zbZXdSovq298JNYN1N8hWv5g3eZbf2+/jbHQozPuOO+4AJjLzrQ09nFzvnuSooJiWdqDr9tprr0W/uRum29/nWU/xYKhW0izJQppC/dwU2OO27aU2W/YkZr4eI5dClV+PY97/XAbuCrkUkpEnEonEyLGqjHzz5s0AHHDAAcDi1V7Bk92LJcNkxpJtSSvBmpHFPnSth/QLLa8KMZZ6tdjPaQWqzJOyVSHN0gCWSpI1lIK2FVTkASgeiOIh5H6+ay1DW721GPlKtJSLL74YgCOPPHJBGa6heWKrWib777//gjJVX99usJWAyxOkuYYnBlsnWVO9vA+63Oe1kYvZ3X777cBiNtdKYVB7YKmfqZ/7dnluo9V5HmYvOFtV3Wr5t7RiZ6HzvD8aU2Sbl+z9U89rKJ2DJ/HTmOLMvLb7A+yzzz7AYibvaaSHUtI6u9c4JXmqvrmxRCKRSPyIYFUZuWYXX61u2fqGEvKKEAfnAAAgAElEQVR7QiAxbTEKD8XWd53n9izVScxD19X2rJYXgtf7lltumVkWgvsre9keaj6UjMrl6Uxbs/3NN98MTGQl9tRKEysZ+BZj9TW+tZ4zcbGW5aCVelhwhjukEfl2cPp0//F6k21ob1TiPs5qr2QJE7br8vS1lSuvvJJ54H3FPTN8DUTPvdZoxWBvvPFGYLEt1mXvz9ND3v2e2rRZfQsWazfu462yfZuzWeAarK/riF27/bq2kXuIvuDrJmL9KkvP3tduPInWkFYq+7nGJfXDaR5705CMPJFIJEaOVWXkgtivb4TsqTDFBC+88MIt15577rkAHHzwwQA84xnPACYeCypTjEMsWfYt2efFlsSOLrvssgV127Bhw5Z7yl7lK/diabrXPFtYiaWIuer+biP3LbZqO6sYgmZ3MWmxL832L3zhCwE45ZRTgAl7Ovvss4EJ29q0aRMAhx12GLDYxgkT1tHaQEL23NYmHLPg8ssvBybPTu3S8auuugqA448/HoBnPvOZW65V/1C/2G+//YCFEX2wmM06k3et5vrrrwcmsr366qu3lPXpT38amLRZcpYd/aabbpq57UNQuWKu3lcEeYyoDbUHiZ7xpZdeCkz6gPqO5PCNb3wDmMja+4RvGadYC703Bx100JZ7euSt+6p75PQ80Dvp36+55hoAbrjhBgAOP/xwAE466aQt5x577LELrmkly2ptKqK+1doMQmPUhz70oS3HpLFcccUVC8pQXWbxe6+RjDyRSCRGjphnpTiRSCQS6wfJyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLkyIE8kUgkRo4cyBOJRGLk+JEeyCOiRMSmGc47tD93h9Wo19ZCRJwWEedN+f2siHjtatZpbIiIqyPilLWuRyIxDetyII+IkyLiyxFxd0TcERFfiohnrXW91ivmlVcp5cWllA9OKXfqRLDayH6xddBPTg9GxH0RcWdEfDYiDl7req0FtoUs1oL4rbuBPCJ2B/4O+C/AXsBBwBnAQ2tZr/WKbSWv9aZ9jL1frDd5AqeWUnYFDgBuppPrjypGL4t1N5ADRwGUUj5WSnm0lPJgKeUfSikXRcQREfGPEXF7RNwWEX8VEXvqwn52fXNEXNSztjMj4vHV778ZETdGxOaIeF1904j4FxFxYUTcExHXRcTpq9bilaEpL50QEe/o2cZVEfHi6vjZEfH6/v/Teob7xxFxB3Am8H7gOT1buWuV2+WY1i9Oi4jzprRzj4j48/7Z3xARfxAR2/e/Te1TNSLiKX3Zr+y/HxgRfxMRt/bHf6U69/SI+EREfCQi7gFO25bCmRellO8DnwCOhqXfg4j4hYi4ppfX7/wwmZ4GZLFHRHyof77XRMRbI2K7/rft+u/XRMQt/Xl79EV9sf+8q393nrOt674eB/LvAo9GxAcj4sUR8cTqtwD+E3Ag8FTgYOB0u/7lwD8DDgOOpX+BIuKfAW8Gfgo4EvDOdz/wC8CewL8AfjEiXrrVWrXtME1eACcC3wH2Bv4I+POIiEZZJwJXAvsCPw+8AfhKKWXXUsrg4LaKWEk7Pwg8AmwCngm8CHh9/9ssfYqIOA74B+CXSykf71/ovwX+iU47eCHwaxHx09VlL6EbGPYE/mr+pm87RMQuwCuAr/aHmu9BRBwNvBd4NR173YOu7T8UGJDFf6Fr4+HA8+nk8q/6307r/07uf98V+JP+t+f1n3v2785XtnXdKaWsuz+6F+ovgevpXsDPAPsNnPdS4MLq+9XAz1ff/wh4f///B4C3V78dBRRgU6MO7wL+uP//0P7cHdZaNsuRF11Hu7w6b5e+Hfv3388GXt//fxpwrZV7GnDeWrdvJe3sf38I2Ln6/VXAFxr3GOpTZ/T3PLk6fuKAvP498Bf9/6cDX1xrmTXaeDVwH3BXL8fNwNMb59bvwe8CHzM5/wA4Za3btLVlAWzf95ujq3P/L+Ds/v//H/il6rcnAw8DO6zFeLEeGTmllG+XUk4rpWwAjqFjS++KiH0j4uO9enwP8BE6Blbjpur/B+hmSvoyrqt+u6a+KCJOjIgv9GrU3XRs1Mtel2jJq//5puq8B/p/d2UY1zWOrwvM2c6NwI7AjRFxV28i+q90Wgcz9qk3AF8upXyhOrYROFBl9uX+Nt3EIaxneb60dFrWTsAbgXMiYv8l3oMF71Av59tXu+LbAItkAWwAHsfCceIaJhrIgQO/7cDC579qWJcDeY1SymV0LOwYOhW4AMeWUnanU/9bZgLHjXRqs3CI/f5ROoZ3cCllDzr78KxlrxuYvJZ9+RLf1w2W0c7r6JjV3qWUPfu/3UspT+t/n6VPvQE4JCL+2Mq9qipzz1LKbqWUf15Xc77WrR5Kt97wSeBR4CSmvwc30g1wAETEzsCTVrfG2w4mix+nY9gbq1MOAW7o/9888NsjdIulq/7c191A3i8ovSkiNvTfD6ZThb8K7EavBkXEQcBvLqPovwZOi4ije1vY79nvuwF3lFK+HxHPBn5upW1ZDSwhr5XiZmBDRDxuK5S1IszbzlLKjXS27f8nInbvF6mOiIjn96fM0qfupVt3eV5EvL0/9jXgnoh4S0TsHBHbR8QxMTJ3yOjwEuCJwLeZ/h58Ajg1Ip7b94kzGCHZacFk8S26MeNtEbFbRGwEfoNOYwP4GPDrEXFYROwK/CFwZinlEeBW4DE62/mqYN0N5HQvzYnA+RFxP92L+i3gTXQd5zjgbuCzwCdnLbSUchadGv6PwOX9Z41fAn4/Iu6lswX+9cqasWqYJq+V4h+BS4CbIuK2rVDeSrCSdv4CnZp8KXAn3YB0QP/bTH2qlHIX3UL5iyPiP5ZSHgVOBZ4BXAXcBvwZ3eLYGPC3EXEfcA/wNuC1pZRLmPIe9L//MvBxOnZ+L3ALI3EBnYKWLH6ZbvH3SuA8Om3lA/01HwA+TOehchXw/f58mZzeBnypN7v9+LZuQPSG+kQikVgWeiZ6F3BkKeWqta7PjzLWIyNPJBLrFBFxakTsEhFPAN4BXEzn+ZFYQ+RAnkgkloOX0C30baaLx3hlSbV+zZGmlUQikRg5kpEnEonEyLGqiXw++MEPTqX/rh089thjAOyyyy5bjm2//fYAbNzYuXAecEDnfPCEJzwBgF133XXBedtt181VitZ+5JFHALjnnnsAuP32Lp7hqqu6tZprrrlmQXkAd93VpRnZbbfdFtSrhde+9rUzu2S95z3vmSoT1V9Qu84666wtx/beu4vXOO644wA49dRTAXj847s0M2eeeeaC7zvvvDMwkcXhh3deUs9/fueR9/nPfx6Ar33tawBceeWVADzxiZOoeMl/KVkIv/IrvzKzTL7+9a8vq58MQXLba6+9ANhjj86ZZKeddgLgcY/rPColT89aoHt8//vfB+D+++8H4M477wQm/afuJzr3Bz/4wYI6CH6P448/flmue7/6q7862HCV6/cTXv7yl2/5X3U75JAujEJ9R+/NLbfcAsAHPtA5Z3z3u98FJn3rRS96EQB77tllbHj00UcBuPXWWwG48cYbgYlcYSLLus/CpO/483z3u989s1w+/OEPz2RS8H76tKc9bdE5koXapnFnxx13BODhhx8G4KGHHlrwXe+R+obGi5tvvnnBcfVBgAceeGDBPVSW5KkyJZvXvOY1U2WSjDyRSCRGjnWRWlOzjmZNfYol1DOZWLGuufzyy4HJjCZoFhU0iwpiZmIxmhn32WcfYMIs6v91L7E5XXvUUUcBixnXSqCyda9LL710we/PeMYztvwvdiyWddNNXbT69ddfD8CDDz644LggtiqmfuGFFwLwpCd1wXrHHnssMJGlWChMGKoYqZ6Z6i1msTVl4v1ErEUyUjtg8nx1zW233bbgWh13Rq4yvRxB99D5YlYw6WPOqgT1sa0lE5Wj57PDDt3r/NznPheYaF41G9X7c/fddwOTPiLWqPY8+clPBib97L777gPgy1/+8oKy1VfEYtWn1Ofqe6lekrm0g/PPPx+YyG1rwJ/zpk2bFty7Hh/UfzSGXHddl4VAz8/Zsj51XH1eZevekonuJRnCRM6yCKjv6NojjjgCWCjHaUhGnkgkEiPHmjJyzZaa+cQoxFzEyIds5IJmMDElZ+KaPfW77Ji6TjOhrtNx1aX+TbOoylCZ3/jGN4CJHXEl0Oyue37zm98E4LDDDltQP7EcmDDpK664ApiwJWeNkp1s3dI0NOvfcIPSSHTQ89H1Ylt1WWIzbufcfffdgYm9cCVoaWy6tzNSmMjRP9027vV2Bi64hqF7SdZ1PSQvt8t6v1ku3BauNqjOxx9//ILjQzZzl6VYovdtPWuVrXv7e6PnqzZJLjW71ns8pMUAnHDCCcBkTWYlcCYuzUJwTbyus/dpPVu1xWXkWqi+S9NQeUOahsY0nasyJVdp/9K2l0Iy8kQikRg51oSROyvQbK7jmsFlY5JdDxbPjrJTaVbVzOasRMf16fYvsSlnxPUxzdT33nvvgnrNy7Cm4bOf/SwAJ5988oJ6//3f/z0AX/ziF7ecK9bxwhe+EJiwKV0j2cjGreNqo2Qqmel3eSycd163bWfdzle96lULytCz0nNpMfXlwPuJnoOOO3Oqn5nYn871erTssTpvqeudxcFizdLt7rN6+CwFla/nsWFDl5BQWprWlNxLqYb6gq5xbUH38Ha6rN2rx72D6t/UfslebFSybXndzAJn4sccc8yC+okBq/51/ZxRez3cJu5jT6tv1Rqil+vapZi4vH/0XORRthSSkScSicTIsaqMvGUT13cxSWfiNXty7xPBGbazNl95ds8B9wmtmZbK0G/O5twXdCXYvHkzMGHZYj6yH55zzjnAxKME4ClPeQoA++2334L6uefGvvvuO3hPtc+vO/TQQ4GJBiIPB5j4mp922mnAYvv71vBAcAarMsWq3M+3hjNrX1tpaQotRt5C3Y/cP1+/uX+5e7PMCjE6eQqJtckbSe+LrzXV3kaqi9ZFXEMV1O6WJ45krjbdcccdC+qoPlVfq/qKoatst03PA7eJ612UDCSzob6ifuZ9RG1RGwWV7ZqG2uN2eB0f0jjcy0vvv/rOC17wglaTF5Yz01mJRCKRWLdYVUbeiuTSrClGIUYu1OzOZzDNsG5n0yyqT53vNk/3atH5NRsU01L9tFKvc+RLq9l0OXB/ZrdvataX94rY90EHTfa8FdNWPX19QAzBV9NbnhxuV5QNtvYeEgtU9NrBBx+8oCzJVf6wy4H3D1+3UD18bWKIPbvm5fZQv8aZuNvlHbUd1P3Z3VNKHiLzMnI9R8UU6HmJDddeRfV9ahmoHeoL6l+Srdqg47qHa6P+qfLkrz8U2SlfdX26TVprY8uBypCfuOrTehZD8Ohvr7d7n0gW7sUi6LuPVUNrJGLruubaa68FJs/jfe97HwAvfen0feCTkScSicTIsSaM3KPj9F12LDGPIUbh0WytKDqHM3HNlrq3WN4Q89Lsrvq5xiDUeTfmhcoQu5avtxiS/MmVF2IIbotreac4I/ccIc5q6lwreg7KzSF7uhiq56dYDtRP3Mbv9dHv0/qA2z39uMvEbftu53Sbe12+9yn3dxe05rBcqByxNmlvHjGq5+Q2W5j0I8Hr6H7gHvnaiq7V+dI6armoD+g32cr93vPIRfVpxYHouL8DNTw2wLW2Vh4U17QkW3/e7jlXQ8ekVUkG+nzqU5/abnx9j5nOSiQSicS6xZp4rWgG1MzlPp6es6BeaXbPF52rWdP9MwX36XTG6HbYmlGI0chG7jYw5UsYmnFnhdupBZUpO7xYWM10VQ8dm9WvvbVKr3L06RGUMPxsYDFjnceP3G2TgjNx99euz2/5BLtvt9v0HbKDOrsdel6tqOIhT6h5oPdDHieuLQiyU7v2OlQ3ebQoEleQbD0eQHZsX3ua1vedueq7y8cji2eBv+8e9era55DXml/jfUb1dabt+VLcG8/HsfqdVT3EvLVu4Pb0aZp3jWTkiUQiMXLkQJ5IJBIjx5osdroq0zIrDLmItUwPOu5pH1vh0VJzpGJ54EOtXql+7n7oZh0tQi0HbqKQWqZ2qD4yP6kutWrobfPFQtXP04dqYXVoUbk+byhgo2WW8c954GYOX7DyBThXm+tzXL1t1V/whV71PT0PD2Kpg0XcNKXFL7loLnXvpeCLuypfdZDpSQtnfh0sNkV4+LkHLblZqOXWK/kMpTRwFzs3w+i5auF8JZi2GF3/PoShflQfV5t8AV8mFt8swp0I6uskE1/gVVCfZHLSSSc167ugjjOdlUgkEol1i1Vl5HKLaqUh9cRVQ476zrBaocT6XaxF9xbj9UVTZx71PX2h1FmNytJ2ccuBtqpzBq5ZXMclGy161qzB3aOGwqRh8SKt7uEbZUhmHr5dBwRJJi33NT9vOVAbPXTaEzk5u6pZd0tjEDzZmge+KODJ+4Wew9ACpgeTSUNT8jE9y2c+85ntxk/B6aefDsD+++8PLA5m04KZy6V+bg53K3QXVGen7p7ofcXlA4sXjFt9ZNZNFGooVYU/Tx9LHLXG4O6GLe1d9fdAIB+/1HYt7kojqjURd9vUtQceeCAw0f4VjLcUkpEnEonEyLGmNnKfPVssasim6LY8t0NpxnV3MX13m54wFFSic5ViUixE95Kt+dvf/vZgu6fBXTLVDrmFtTbOmBbuq3OcmbkcfWOC1hqGh/rDYjlJRpLFShIgueuiM3HXBrw/1fAAFnfFE2sSA9fvsjPreoW/exBbLQfVQwEvStmgDT+0sXed8Gw5UF1kV22ldBb0vQ59b7l0toJ0xOb17NXH/H1zzXaIfTrjlazlVunJqZYD195bY8e0tRvvK56GwN0m3Y1a3/XuurWg7iseYKbn4NtbetqFFpKRJxKJxMixqoxc2xd52Glr9tQMVtvOdEyznj6d3XvZOq6Z0G3kYjU6v15NFjtzm7HYnNsLlwNnOi0beSuNaA1Pp9vy8BFrbm0a6/bgaZ48rRD8FgOeBQoMkb1Q8PUL1xhqLaXlYSA7sjyP9OkeB84w3f7s6wow6TNi955eQfdyL5ZZ4cnP1F5PQuUb+dZbq4nxuVeHs8/WZg8emu/b2un8mn163/VnouOtbfamocWwfV3Fz6/7SquN7tEjeFpi1wg9IG+ofTrXA808ZcisSEaeSCQSI8eabPXW8nt2ZismPLSa7fYqwW3empll3/ZNcz0NrqdKrY+JUTnL1LX77LPPQGunw+3Aao8zJ7FohVLXLKtlC/ft7zwc3W3p/ruHbQ8lBXN5+rOcZxs82Wvdp9ZX+qdtFqFnpfBp938eYmbQTg7lKWhVxyF/aXmrOPPWM/3yl78MwMtf/vKGBIah6+Vv7YxRbdZ5rTQFMPEM0nNzby5/jr5Zgq/V6B0diglxrdJ91j1N9HLQSlvQspkLQyH6rpXoHNVXGpfGJddqXCOftk7U8grya2fdvDwZeSKRSIwcq8rIxVC0HZP7kWumk9+tJ7SCxUlk3K4m5uQzsEfkidGKZfq2YXW57qft9nbN1GrXcuDsWTJxH1X5Dqu+te3PI/48Es2Zt5iQ+1A70/WNeIc2j/Xo0VYU5nKgtir5k29+oI00xDx9vQQmdmMxaMnN26R2SDaSgc4X01PZetZDG06onuqDbk9Wmerfy4X6rKdd1TOQPHwbNnlAQDuK2qN7PamTa64e2ekRnkPwc9w7SRrYPPCNMdwLxMeS+rm1bOFqu7Qvj+nwjVh87WZabIowbYNmgEsuuQSAE044YbDdW66b+msikUgk1j1WlZG7T6psYpo9tcovf1v9XvvBalb0qESH28h81nTvBI8Ek+0NJjOzGJUYl2ZT1WUeRuF5THzLOdmp9alNLWobuSC5eppXfYpZuBage3oaXNXJ847U92/Z51sb2s4CeTd99atfBSbsWs9Emo+2l3MPihpqi7fZvVpadne1Q/cWMx+ycbaihD1WoNYclgP5FGstxuss5u1rTUM5ctxjaUjrgsXeE+qXknUrnqNmmu6t4v1Jsq3fuVnhWoneYz13Xwsbit50Rt7yHJM83cPJ14F03rSNvF3u3ndU31ljU5KRJxKJxMixqoxcs4xs5W6Pk2eJmLlQswLPFuZbO7Xu6XZFt6lpddgZBiz2G9W51113HbCyrG1iUZr1ndlIC1CuGH2vo+CksbgPr851/3GH+427jXdokwi3q7vdcCgadFb86Z/+6YI2qizf2mxalJ4zs9bWgG7z9XwgrY0ohJrZuYbjHkhihy1PhaWgjax1vW8o4X3Jt0yExZqqa4TOEHUP1d23s5Pc9F66fbgu0+Eao/IOLQfSUNXHxaqdNft6xdD77XL1KHH3xPJYCt3TtdIhDyn3lvJtDfV8kpEnEonEjwhWlZGfc845ABx55JHAZMNe2ZbFdH1D0prVaaYS+9Ds5+xELEizvc6X3d29LXymHpo9VR/Z8C+++OIFx5cbjQUTlqzZ3j1JPFeMaxaw2G7e2tbK2aXf222EboOtZewsXmW3MhYuB/Kz/qmf+qkFZctG7Jt3D93Dbb6tjaZ9XcDZU2sNxpl8fcw9ZNQvWluGzYqjjz4agOuvv37BcX8Wbuev69jKW+OeLt7ftL6itZpWRO+QZ0ZrPcvz8swTBaz3WTLxMcO9qdzvHdrvfouRexZR31JP1+s8vZezvAuu4c4aBZyMPJFIJEaOVWXkF1xwATDxBfcdTVo5GWobtJi2ZmKPPnQbnmZFsX6PHtMKs0dl1bus6Lerr74amDDxiy66aEF952GfzqZUb93TvS6G/GCdaYsBOjNTmZ7fpeWxIKbkeWDqa8Q2VH+3w8/jtaI2KypT2pSe4aZNm4DFawM1o3MG7qzPo1k9elR1EHNTHdyGXMPtnh4Fqhwy80QwwiQa0324PZpZXjFqY63RtiKh3c/ad4fSp8r2SFldr/WVmpm7R5hrVCrb3+VZINu8mKtrK24r903XYbHt2xm1M2vPaSOofW6vH4JnNW1lZZ11Q/dk5IlEIjFyrCojl01cq9Oy7bpng8+eNdNyzwW/xn023Y9Un77Lh9ieZtmaobe8A7wuntVxFnjZgpif2619J5QanttYcNbkdkOd73bfFqOHxb7A7vcuOFucBccddxwwYS0eTyAPHml2Q7vBuG3c2ZZ7sfjahP/u5bZ2KaqhNR+xVMnv61//ervxU+ARt0N+4nWdPDcNLF4TUP/3nOAtObl3ha73KMjaJ1yy8r7h+YXm8eY599xzAfje974HTGTt+6ZqrJnmq+6/qW2yCDjTdlu5azXTvFaW2rnII6eXQjLyRCKRGDlWlZE//elPByYzs2YlzZYebabj9aq7Zk3Nhs5cPRe3ypTtSdeJCcsWLrYnllfPzm77VBliNWKML3jBC2YRwwJIM3D/cbd/OjOv6+T2Wvf9bcH9+MVenGU6u4HFOWFae6m63/8sOPXUU4GFEb0w0ZoU2SmbsccEwOJ1C2fQrrm57bu13iHZDuUU8ahBPUvZ+mXHVb9eLlSectCIfeo5u//6kH3Vc8uo/Z7/pLWnpK9jqQ76VB1rTcx9uV0+Hp+xHJx11lkL7q8+4+/TLP1Q77G3VVqGIoxdcxjqf7B4F6n6PR3a4QsWZ1r0mJoWkpEnEonEyLGqjFxZ7WT3kYeD54rQ8aFdZjxfi/twuleC72Dt2eukHSh/xZBd3m1dikBVWbLZHnXUUTPLQvAIulbUnvuGD+WyUBtbXhG+Ui7WpE89B987Ud+n7cPYyoYnNrMcKM5A7EpMR/1HzNx36amZkrNT1/Zci3ENyH2HXcatHeFhsUeMtDy163Wve90SEhiG75cpFuptmJaB0G2zngVSGMo8OnQvj5ic5gvu/uTOxFssdRouu+wyYCJj1xDdu8ojWGvofXavL7eFez4ZjVe+5uT9stYKXFvyHYNUX/fCaSEZeSKRSIwcq8rIPSucZj5fUXamMeQH6zuSeF4OZ2TCtGjAug5DK8yeE0Jli83PE9np8B1N3KbpjAMmGoHgni2uUbgvrXsPSHbuN1v71qutfq2esUe9LQcbNmwAFtuvPW+K56Wo+4n7/rZs4c7UW37Wbjt3L6mhe6hfO9tXPvXlwqOQfU9O94Efygap/u2Z+3x3KJeHR+y6vduf8xCT95w9vgvRPDEH/j74GpnXa0gD8feitauVa1rqbx4X43scSOMY8it31u/nzur1lYw8kUgkRo4cyBOJRGLkWFXTikwmSv/qLoNushCGVJKlNg7WNW5W8MVCXa9FBlf76v9dzXYXp3nS2fp9W7+r3pJhvaDpi5Me8CMzlNrhW6f5ZglS83QvXV8v1qheHnwieJjzcuDuqO5e5wuWQ/2j1Q98EdndV1twN9BpgRq+qKxPtWvepFluFtBzdFXezQu1ycJNj62t79x8M5SSoL7ON7WoTZfqZ3Is8AVR1W+ejSVk1pS5ykPy3dV5yOTq7oPuUCF5qu94+geNW36dp1uu+5iPS97/9PusZrhk5IlEIjFyrCojd6Yghtea1YfQWlQRY/KEUB5S7K5BvigztMjgyX383rrXrK5CNVobJru7pBY0teBY10WBCqq7zlW9nemIaaJvJ38AAATISURBVDsTcQ3DNSYFttT3EBt0dtxaPJwFrlG4ttLaVqy+l4eaD23xVWNaMixYvAg9tEDnW5m5m60v7i0XupdkrzY64/U+XdfRkzR5H/CNVVp9XvLwAJyh565j0iI9GZtrXMuB0n74QqPuJVl5Qrm6H/iiuW+ELhmpTF2rsnRcn96XtBhaa4O+yC54SpFjjz12BikkI08kEonRY1UZubv2eRIatxN5ovb6mCc3cpc6P8/P92AjT7xU2/E8zWsr0fw8m+p6WS4D2UHFusXI6zBv35rNWaWzZU/6465asjPq3rKR14Em7iLqtuelbM7T4Pbsliujt3PIFjy0Td0s311T8nsPserWGkor+Gi50PMQy3TXQGfHnggMFq8tub1aLNTXIVrnt1xca63A3zW3HbtteTmQjdxloPdDWr76o2tWsPjd8zGglVDNGXkrkZ/b2GGxhcCD+PRuis0vhWTkiUQiMXKsKiN/0YteBMDZZ5+94LjPdL4qXMMDf3x1vcXAW/Y3P3/IhjrrDDwUgLEUrr32WmASBCM42/fgnCFvEE+q5EmnPPlPy9tF99J5sjvWtnZnGa1tseZJYyvm74mdfK3C7bLTkhK5l5L3F0+mtVRA01A/8YAdwcP6W6mLl4LkoP4ojwbVxVPR+noFLE6C5d5egjNv99wS/Hpn/PVvrbTVbq9fDpRAzdeO1GdbjLyun48hvv2dJ+DzNRB9eloAT3Tn71t9T52r7Qx1zayePMnIE4lEYuRYE68VzZKCb1brbGdoBdztwZ7wydm8M0dfmRaG0l26vdftiMLGjRsXXTsr3Lfbt05zVnPQQQdtuVaMT233zV51rZi6vE+csQ0lx4KJtlAfd4bbSq5fh/XPilbyLmc8ziJr32VP3uX9xVMKOPv3jat9nWTIa8W1RZ2j5+GscLnw9vom2uqX0sSGNghRHVp26SHGCotD8X29SFrUUBpgT6ilenp6APXP5UDt8dgD37TcNYW6fi1NyvuCpwFwP3Nn9ILqUI97vqbg8SJ6dkrVvBSSkScSicTIsaqMXLOQtkRTon2twssP1v01hyKiZEvSZ8v30xMZuY+nZj4xR9mRa/YjxuPbZOlzJUxckD3ak1GJDUsmYi2KJoNJmxVZKsa9efNmYOLfrpSf2gT48MMPB+CQQw4BJivk+jzwwAMXtK+2jzoL8SRU8zBxwaN1fRMRjxnwlMb1MdkY3dboHibOlv1eOk8a29AahXvIuFdWKx5hVng6VLFQlav7qC8pglppl2HCnGVfV2pgfar/SfYqW8zQ/c194wZpH3VEovqq7qF3U+tD6pfzePO49qMxRH1XXi3umVLLRM9W45BvMOHrKbqHy8q1Uvc0q9cAnN1LzirTbftLymGmsxKJRCKxbhHzeBUkEolEYv0gGXkikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHDmQJxKJxMiRA3kikUiMHP8b9ErxHCFG3PAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(28,28, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
