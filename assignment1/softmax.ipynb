{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*ATTENTION: When hand in your homework, all print info has to be kept which means that output results of each cell could be seen in your submissions. Homework scores will be judged by those print info. So show us the best result in your experiment. More details can be found in assignment1_tutor.pdf.\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from MS326.datasets.fashion_mnist.utils import mnist_reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (58000, 785)\n",
      "Train labels shape:  (58000,)\n",
      "Validation data shape:  (2000, 785)\n",
      "Validation labels shape:  (2000,)\n",
      "Test data shape:  (10000, 785)\n",
      "Test labels shape:  (10000,)\n",
      "dev data shape:  (1000, 785)\n",
      "dev labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "def get_mnist_data(num_training=58000, num_validation=2000, num_test=10000, num_dev=1000):\n",
    "    \"\"\"\n",
    "    Load the Fashion_mnist dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw Fashion_mnist data\n",
    "    X_train, y_train = mnist_reader.load_mnist('MS326/datasets/fashion_mnist/data/fashion', kind='train')\n",
    "    X_test, y_test = mnist_reader.load_mnist('MS326/datasets/fashion_mnist/data/fashion', kind='t10k')\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0).astype('uint8')\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_mnist_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **MS325/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.423670\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file MS326/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from MS326.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(785, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ \n",
    "\n",
    "Since the weight matrix W is uniform randomly selected, the predicted probability of each class is uniform distribution and identically equals 1/10, where 10 is the number of classes. So the cross entroy for each example is -log(0.1), which should equal to the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -4.713060 analytic: -4.713068, relative error: 8.690620e-07\n",
      "numerical: -7.838598 analytic: -7.838606, relative error: 5.613333e-07\n",
      "numerical: 0.924386 analytic: 0.924377, relative error: 4.442504e-06\n",
      "numerical: -0.500333 analytic: -0.500345, relative error: 1.251771e-05\n",
      "numerical: 2.752350 analytic: 2.752334, relative error: 2.915553e-06\n",
      "numerical: -7.126037 analytic: -7.126040, relative error: 1.888097e-07\n",
      "numerical: -3.066058 analytic: -3.066067, relative error: 1.504593e-06\n",
      "numerical: -12.775997 analytic: -12.776012, relative error: 5.495890e-07\n",
      "numerical: -0.676468 analytic: -0.676487, relative error: 1.406875e-05\n",
      "numerical: 0.784406 analytic: 0.784403, relative error: 1.735787e-06\n",
      "numerical: 4.585155 analytic: 4.585138, relative error: 1.786150e-06\n",
      "numerical: -0.744476 analytic: -0.744479, relative error: 2.103890e-06\n",
      "numerical: -0.114269 analytic: -0.114272, relative error: 1.362698e-05\n",
      "numerical: -0.087215 analytic: -0.087218, relative error: 1.727395e-05\n",
      "numerical: -2.167370 analytic: -2.167372, relative error: 5.573749e-07\n",
      "numerical: -7.509049 analytic: -7.509055, relative error: 4.452593e-07\n",
      "numerical: 3.270328 analytic: 3.270314, relative error: 2.065813e-06\n",
      "numerical: 5.604211 analytic: 5.604203, relative error: 6.983234e-07\n",
      "numerical: 2.504847 analytic: 2.504830, relative error: 3.362390e-06\n",
      "numerical: 5.090515 analytic: 5.090510, relative error: 4.539290e-07\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from MS326.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.423670e+00 computed in 0.270021s\n",
      "vectorized loss: 2.423670e+00 computed in 0.000000s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from MS326.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-08 reg 5.000000e+02 train accuracy: 0.139897 val accuracy: 0.152000\n",
      "lr 1.000000e-08 reg 1.000000e+03 train accuracy: 0.196534 val accuracy: 0.211000\n",
      "lr 1.000000e-08 reg 5.000000e+03 train accuracy: 0.253983 val accuracy: 0.261000\n",
      "lr 1.000000e-07 reg 5.000000e+02 train accuracy: 0.714586 val accuracy: 0.715500\n",
      "lr 1.000000e-07 reg 1.000000e+03 train accuracy: 0.721379 val accuracy: 0.722500\n",
      "lr 1.000000e-07 reg 5.000000e+03 train accuracy: 0.703948 val accuracy: 0.706500\n",
      "lr 5.000000e-07 reg 5.000000e+02 train accuracy: 0.703948 val accuracy: 0.711000\n",
      "lr 5.000000e-07 reg 1.000000e+03 train accuracy: 0.723586 val accuracy: 0.716500\n",
      "lr 5.000000e-07 reg 5.000000e+03 train accuracy: 0.642724 val accuracy: 0.654500\n",
      "best validation accuracy achieved during cross-validation: 0.722500\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.65 on the validation set.\n",
    "from MS326.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-8, 5e-7, 1e-7]            # Modify it as you wish\n",
    "regularization_strengths = [5e2, 1e3, 5e3]  # Modify it as you wish\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500)\n",
    "        \n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        \n",
    "        train_accuracy = np.mean(y_train == y_train_pred)\n",
    "        val_accuracy = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, reg)] = train_accuracy, val_accuracy\n",
    "        \n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = softmax\n",
    "\n",
    "        \n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.696200\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$\n",
    "\n",
    "True.\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "\n",
    "SVM loss can be strictly equal to zero for data points with big enough margin. But logarithmic loss (Softmax classifier loss) is always positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(28,28, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MS326]",
   "language": "python",
   "name": "conda-env-MS326-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
